__license__   = 'Postcardware (http://en.wikipedia.org/wiki/Postcardware), contact author for postal address.'
__copyright__ = '2011, Olek Poplavsky <woodenbits at gmail.com>'

from calibre import strftime
from calibre.web.feeds.news import BasicNewsRecipe
import logging
import sys

class Readitlater(BasicNewsRecipe):
    title                 = 'Readability'
    __author__            = 'Olek Poplavsky'
    description           = '''Custom news feeds for Readability. Go to readability.com to
                               setup up your account, then add some articles to your reading list
                               and/or favorites. Fill in your account username and password.'''
    publisher             = 'Woodenbits'
    category              = 'news, custom'
    oldest_article        = 90
    max_articles_per_feed = 100
    no_stylesheets        = True # default False
    use_embedded_content  = False # default None
    needs_subscription    = True # default False
    auto_cleanup = True # default False
#    delay = 0.2 # default 0
    simultaneous_downloads = 5 # set to 1 anyway if delay is > 0
    timeout = 120.0 # in seconds, default 120

    INDEX                 = u'https://www.readability.com'

    extra_css = '''
                    h1{font-weight:bold;font-size:x-large;}
                    h2{font-weight:bold;font-size:large;}
                    h3{font-weight:bold;font-size:normal;}
                    h4{font-weight:bold;font-style:italic;font-size:normal;}
                    h5{font-weight:bold;font-style:italic;font-size:normal;color:#333333;}
                '''

    def get_browser(self):
        br = BasicNewsRecipe.get_browser(self)
        if self.username is not None and self.password is not None:
            login_url = self.INDEX + u'/login'
            br.open(login_url)
            br.form = list(br.forms())[0]
            br['username'] = self.username
            br['password'] = self.password
            response = br.submit()
        return br

    def get_feeds(self):
        self.report_progress(0, ('Generating list of feeds...'))
        lfeeds = []

        base_url = self.INDEX + u'/' + self.username
        reading_list_url = base_url + u'/latest'
        favorites_url = base_url + u'/favorites'
        self.report_progress(0, (favorites_url))
        lfeeds.append((u'Reading List', reading_list_url))
        lfeeds.append((u'Favorites', favorites_url))

        return lfeeds

    def parse_index(self):
        totalfeeds = []
        lfeeds = self.get_feeds()
        for feedobj in lfeeds:
            feedtitle, feedurl = feedobj
            self.report_progress(0, ('Fetching feed')+' %s...'%(feedtitle if feedtitle else feedurl))
            articles = []
            soup = self.index_to_soup(feedurl)
            ritem = soup.find('ul',attrs={'id':'rdb-reading-list'})
            for item in ritem.findAll('li'):
                description = ''
                processed_article_tag = item.find('a',attrs={'class':'list-article-title'})
                article = item.find('div',attrs={'class':'article'})
                if article:
                    description_tag = article.find('p')
                    date_tag = article.find('time')
                    author_tag = article.find('span',attrs={'class':'article-domain'})
                    url         = article.find('a',attrs={'title':'Read this article'})['href']
                    if not url.startswith("http"):
                        url = self.INDEX + url
                    title_tag   = article.find('h3')
                    title       = self.tag_to_string(title_tag)
                    date        = self.tag_to_string(date_tag)
                    description = self.tag_to_string(description_tag)
                    author      = self.tag_to_string(author_tag)
                    articles.append({
                                      'title'       : title,
                                      'date'        : date,
                                      'author'      : author,
                                      'url'         : url,
                                      'description' : description
                                    })
            totalfeeds.append((feedtitle, articles))
        return totalfeeds

    def preprocess_html(self, soup):
        for original_article_tag in soup.findAll('a', attrs={'id':'article-url'}):
            original_article_url = original_article_tag['href']
            if original_article_url is not None:
                import re
                original_article_url = re.sub(r"^https?://", '', original_article_url)
                del original_article_tag['style']
                original_article_tag.contents[0].replaceWith('Original:&nbsp;&nbsp;' + original_article_url)
                # original_article_tag.replaceWith(original_article_url)
        return soup

    def populate_article_metadata(self, article, soup, first):
        if first:
          body = soup.find('body')
          if article.summary:
            body.insert(1,'<h6>Summary:&nbsp;&nbsp;' + article.summary + '</h6>')
          if article.author:
            body.insert(1,'<h3>Author:&nbsp;&nbsp;' + article.author + '</h3>')
          body.insert(1,'<h2>Title:&nbsp;&nbsp;' + article.title + '</h2>')
          body.insert(1,'<h6>Original:&nbsp;&nbsp;<a href="' + article.url + '>' + article.url +'</a></h6>')

